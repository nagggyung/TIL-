{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10270839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\project\\urop-project\\face_recognition\\recognition_mosaic\\mtcnn\\mtcnn\n"
     ]
    }
   ],
   "source": [
    "cd C:\\project\\urop-project\\face_recognition\\recognition_mosaic\\mtcnn\\mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0558ea5",
   "metadata": {},
   "source": [
    "<h1> Collect images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c75268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-0faa361c7a19>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Colleting Samples Complete!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "from os.path import isdir\n",
    "\n",
    "# 얼굴 저장 함수\n",
    "face_dirs = 'images/'\n",
    "face_classifier = cv2.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "# 얼굴 검출 함수\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    # 얼굴이 없으면 패스!\n",
    "    if faces is():\n",
    "        return None\n",
    "    # 얼굴이 있으면 얼굴 부위만 이미지로 만들고\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    # 리턴!\n",
    "    return cropped_face\n",
    "\n",
    "# 얼굴만 저장하는 함수\n",
    "def take_pictures(name):\n",
    "    # 해당 이름의 폴더가 없다면 생성\n",
    "    if not isdir(face_dirs+name):\n",
    "        makedirs(face_dirs+name)\n",
    "\n",
    "    # 카메라 ON    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        # 카메라로 부터 사진 한장 읽어 오기\n",
    "        ret, frame = cap.read()\n",
    "        # 사진에서 얼굴 검출 , 얼굴이 검출되었다면 \n",
    "        if face_extractor(frame) is not None:\n",
    "            \n",
    "            count+=1\n",
    "            # 200 x 200 사이즈로 줄이거나 늘린다음\n",
    "            face = cv2.resize(face_extractor(frame),(200,200))\n",
    "            # 흑백으로 바꿈\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 200x200 흑백 사진을 faces/얼굴 이름/userxx.jpg 로 저장\n",
    "            file_name_path = face_dirs + name + '/user'+str(count)+'.jpg'\n",
    "            cv2.imwrite(file_name_path,face)\n",
    "\n",
    "            cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Cropper',face)\n",
    "        else:\n",
    "            print(\"Face not Found\")\n",
    "            pass\n",
    "        \n",
    "        # 얼굴 사진 100장을 다 얻었거나 enter키 누르면 종료\n",
    "        if cv2.waitKey(1)==13 or count==300:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Colleting Samples Complete!!!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 사진 저장할 이름을 넣어서 함수 호출\n",
    "    take_pictures('Nagyung')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c2b06",
   "metadata": {},
   "source": [
    "<h1>train</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca40642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10aba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cascade\n",
    "face_cascade = cv2.CascadeClassifier('haar_face.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39b558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금 내 코드 파일\n",
    "BASE_DIR = 'C:/project/urop-project/face_recognition/recognition_mosaic/mtcnn/mtcnn'\n",
    "# 이미지 경로\n",
    "image_dir = os.path.join(BASE_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342e0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_id = 0\n",
    "label_ids = {}\n",
    "y_labels = []\n",
    "x_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5a7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n"
     ]
    }
   ],
   "source": [
    "# 이미지 경로랑 이름, label 다 print\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(root).replace(\" \", \"-\").lower()\n",
    "            #print(label, path)\n",
    "            \n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[label]\n",
    "            print(label_ids)\n",
    "                \n",
    "            \n",
    "            # y_labels.append(label) # some number\n",
    "            # x_train.append(path) # verify this image, turn into a numpy array, GRAY\n",
    "            \n",
    "            pil_image = Image.open(path).convert(\"L\") #gray scale\n",
    "            size = (550, 550)\n",
    "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            image_array = np.array(pil_image, \"uint8\")\n",
    "            #print(image_array)\n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.5, minNeighbors=5)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h, x:x+w] #roi에 얼굴 좌표 넣는다.\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "                \n",
    "#print(y_labels)\n",
    "#print(x_train)\n",
    "\n",
    "with open(\"labels.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_ids, f)\n",
    "\n",
    "#Train OpenCV\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(\"trainner.yml\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb56ac",
   "metadata": {},
   "source": [
    "<h1>Face Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d673a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1de84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cascade\n",
    "face_cascade = cv2.CascadeClassifier('haar_face.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model = recognizer.read(\"trainner.yml\")\n",
    "\n",
    "# 피클로 라벨이름 불러오기\n",
    "labels = {\"person_name\": 1}\n",
    "with open(\"labels.pickle\", 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    # key value pairs\n",
    "    labels = {v:k for k,v in og_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49c0fd",
   "metadata": {},
   "source": [
    "<h1>Recognition & Mosaic</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa02b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'font' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-be7570bb9b78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[1;31m#frame[y:y+h, x:x+w] = face_img # 인식된 얼굴 영역 모자이크 처리\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mdisplay_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Stranger'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstroke\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'font' is not defined"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "from math import sqrt\n",
    "detector = MTCNN()\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    min_score = 999  \n",
    "    #Use MTCNN to detect faces\n",
    "    faces = detector.detect_faces(frame)\n",
    "    if faces != []:\n",
    "        for person in faces:\n",
    "            bounding_box = person['box']\n",
    "            #for \n",
    "            \n",
    "#             print(\"faces:\" + str(faces))\n",
    "#             print(\"[0]: \" + str(bounding_box[0]))\n",
    "#             print(\"[1]: \" + str(bounding_box[1]))\n",
    "#             print(\"bounding box:\" + str(bounding_box))\n",
    "            x = bounding_box[0]\n",
    "            y = bounding_box[1]\n",
    "            w = bounding_box[2]\n",
    "            h = bounding_box[3]\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,155,255), 2)\n",
    "            #print(x,y,w,h)\n",
    "            #circle(frame, (x,y), 반지름, 색깔, thickness)\n",
    "            #conf = faces[0]['confidence']\n",
    "            #print(conf)\n",
    "            #implements recognizer 얼굴인식기 구현\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "            if conf >= 45 and conf <= 85:\n",
    "                print(labels[id_]+ str(conf))\n",
    "                print(id_)\n",
    "                print(labels[id_])\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                name = labels[id_]\n",
    "                color = (255, 0, 0)\n",
    "                stroke = 2\n",
    "                display_string = str(int(conf))+'% '+ name\n",
    "                cv2.putText(frame, display_string, (x,y), font, 1, color, stroke, cv2.LINE_AA)\n",
    "            else:\n",
    "                #print(\"none:\" + str(conf))\n",
    "                #face_img = frame[y:y+h, x:x+w] # 인식된 얼굴 이미지 crop\n",
    "                #face_img = cv2.resize(face_img, dsize=(0, 0), fx=0.04, fy=0.04) # 축소\n",
    "                #face_img = cv2.resize(face_img, (w, h), interpolation=cv2.INTER_AREA) # 확대\n",
    "                #frame[y:y+h, x:x+w] = face_img # 인식된 얼굴 영역 모자이크 처리\n",
    "                display_string = 'Stranger'\n",
    "                cv2.putText(frame, display_string, (x,y), font, 1, color, stroke, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21992a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none:68\n",
      "none:36\n",
      "none:70\n",
      "none:70\n",
      "none:69\n",
      "none:70\n",
      "none:72\n",
      "none:32\n",
      "none:72\n",
      "none:72\n",
      "none:72\n",
      "nagyung77\n",
      "0\n",
      "nagyung\n",
      "none:70\n",
      "none:71\n",
      "none:71\n",
      "nagyung80\n",
      "0\n",
      "nagyung\n",
      "none:68\n",
      "nagyung77\n",
      "0\n",
      "nagyung\n",
      "none:70\n",
      "nagyung77\n",
      "0\n",
      "nagyung\n",
      "none:64\n",
      "none:73\n",
      "none:69\n",
      "nagyung76\n",
      "0\n",
      "nagyung\n",
      "none:69\n",
      "none:66\n",
      "nagyung79\n",
      "0\n",
      "nagyung\n",
      "none:65\n",
      "nagyung79\n",
      "0\n",
      "nagyung\n",
      "none:66\n",
      "none:67\n",
      "none:67\n",
      "nagyung79\n",
      "0\n",
      "nagyung\n",
      "none:67\n",
      "nagyung77\n",
      "0\n",
      "nagyung\n",
      "none:67\n",
      "nagyung77\n",
      "0\n",
      "nagyung\n",
      "none:67\n",
      "nagyung81\n",
      "0\n",
      "nagyung\n",
      "none:68\n",
      "nagyung81\n",
      "0\n",
      "nagyung\n",
      "none:68\n",
      "nagyung81\n",
      "0\n",
      "nagyung\n",
      "none:67\n",
      "none:68\n",
      "nagyung80\n",
      "0\n",
      "nagyung\n",
      "none:66\n",
      "nagyung80\n",
      "0\n",
      "nagyung\n",
      "nagyung81\n",
      "0\n",
      "nagyung\n",
      "nagyung80\n",
      "0\n",
      "nagyung\n",
      "nagyung79\n",
      "0\n",
      "nagyung\n",
      "none:64\n",
      "none:64\n",
      "none:66\n",
      "none:67\n",
      "none:66\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "from math import sqrt\n",
    "detector = MTCNN()\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    min_score = 999  \n",
    "    #Use MTCNN to detect faces\n",
    "    faces = detector.detect_faces(frame)\n",
    "    if faces != []:\n",
    "        for person in faces:\n",
    "            bounding_box = person['box']\n",
    "            #for \n",
    "            \n",
    "#             print(\"faces:\" + str(faces))\n",
    "#             print(\"[0]: \" + str(bounding_box[0]))\n",
    "#             print(\"[1]: \" + str(bounding_box[1]))\n",
    "#             print(\"bounding box:\" + str(bounding_box))\n",
    "            x = bounding_box[0]\n",
    "            y = bounding_box[1]\n",
    "            w = bounding_box[2]\n",
    "            h = bounding_box[3]\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,155,255), 2)\n",
    "            #print(x,y,w,h)\n",
    "            #circle(frame, (x,y), 반지름, 색깔, thickness)\n",
    "            #conf = faces[0]['confidence']\n",
    "            #print(conf)\n",
    "            #implements recognizer 얼굴인식기 구현\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "            min_score = conf\n",
    "            if min_score < 500:\n",
    "                #????? 어쨋든 0~100표시하려고 한듯 \n",
    "                conf = int(100*(1-(min_score)/300))\n",
    "                if conf >= 75:\n",
    "                    print(labels[id_]+ str(conf))\n",
    "                    print(id_)\n",
    "                    print(labels[id_])\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    name = labels[id_]\n",
    "                    color = (255, 0, 0)\n",
    "                    stroke = 2\n",
    "                    display_string = str(int(conf))+'% '+ name\n",
    "                    cv2.putText(frame, display_string, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),2, cv2.LINE_AA)\n",
    "                else:\n",
    "                    print(\"none:\" + str(conf))\n",
    "                    face_img = frame[y:y+h, x:x+w] # 인식된 얼굴 이미지 crop\n",
    "                    face_img = cv2.resize(face_img, dsize=(0, 0), fx=0.04, fy=0.04) # 축소\n",
    "                    face_img = cv2.resize(face_img, (w, h), interpolation=cv2.INTER_AREA) # 확대\n",
    "                    frame[y:y+h, x:x+w] = face_img # 인식된 얼굴 영역 모자이크 처리\n",
    "                    display_string = 'Stranger'\n",
    "                    cv2.putText(frame, display_string, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6833f876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\project\\\\urop-project\\\\face_recognition\\\\recognition_mosaic\\\\mtcnn\\\\mtcnn'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f23733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
